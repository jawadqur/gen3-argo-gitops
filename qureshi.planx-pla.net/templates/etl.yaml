kind: ConfigMap
apiVersion: v1
metadata:
  name: etl-mapping
data:
  etlMapping.yaml: |
    mappings:
      - name: dev_case
        doc_type: case
        type: aggregator
        root: case
        props:
          - name: submitter_id
          - name: project_id
          - name: disease_type
          - name: primary_site
        flatten_props:
          - path: demographics
            props:
              - name: gender
                value_mappings:
                  - female: F
                  - male: M
              - name: race
                value_mappings:
                  - american indian or alaskan native: Indian
              - name: ethnicity
              - name: year_of_birth
        aggregated_props:
          - name: _samples_count
            path: samples
            fn: count
          - name: _aliquots_count
            path: samples.aliquots
            fn: count
          - name: _submitted_methylations_count
            path: samples.aliquots.submitted_methylation_files
            fn: count
          - name: _submitted_copy_number_files_on_aliquots_count
            path: samples.aliquots.submitted_copy_number_files
            fn: count
          - name: _read_groups_count
            path: samples.aliquots.read_groups
            fn: count
          - name: _submitted_aligned_reads_count
            path: samples.aliquots.read_groups.submitted_aligned_reads_files
            fn: count
          - name: _submitted_unaligned_reads_count
            path: samples.aliquots.read_groups.submitted_unaligned_reads_files
            fn: count
          - name: _submitted_copy_number_files_on_read_groups_count
            path: samples.aliquots.read_groups.submitted_copy_number_files
            fn: count
          - name: _submitted_somatic_mutations_count
            path: samples.aliquots.read_groups.submitted_somatic_mutations
            fn: count
        joining_props:
          - index: file
            join_on: _case_id
            props:
              - name: data_format
                src: data_format
                fn: set
              - name: data_type
                src: data_type
                fn: set
              - name: _file_id
                src: _file_id
                fn: set
      - name: dev_file
        doc_type: file
        type: collector
        root: None
        category: data_file
        props:
          - name: object_id
          - name: md5sum
          - name: file_name
          - name: file_size
          - name: data_format
          - name: data_type
          - name: state
        injecting_props:
          case:
            props:
              - name: _case_id
                src: id
                fn: set
              - name: project_id
        target_nodes:
          - name: slide_image
            path: slides.samples.cases
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: etl-cronjob
spec:
  schedule: "0 0 1 * *"
  jobTemplate:
    spec:
      backoffLimit: 0
      template:
        metadata:
          labels:
            app: gen3job
        spec:
          shareProcessNamespace: true
          affinity:
            nodeAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
                - weight: 100
                  preference:
                    matchExpressions:
                      - key: karpenter.sh/capacity-type
                        operator: In
                        values:
                          - on-demand
                - weight: 99
                  preference:
                    matchExpressions:
                      - key: eks.amazonaws.com/capacityType
                        operator: In
                        values:
                          - ONDEMAND
          volumes:
            - name: signal-volume
              emptyDir: {}
            - name: creds-volume
              secret:
                secretName: "peregrine-dbcreds"
            - name: etl-mapping
              configMap:
                name: etl-mapping
            - name: fence-yaml
              configMap:
                name: useryaml
          containers:
            - name: gen3-spark
              image: quay.io/cdis/gen3-spark:master
              ports:
              - containerPort: 22
              - containerPort: 9000
              - containerPort: 8030
              - containerPort: 8031
              - containerPort: 8032
              - containerPort: 7077
              livenessProbe:
                tcpSocket:
                  port: 9000
                initialDelaySeconds: 10
                periodSeconds: 30
              env:
              - name: DICTIONARY_URL
                valueFrom:
                  configMapKeyRef:
                    name: manifest-global
                    key: dictionary_url
              - name: HADOOP_URL
                value: hdfs://0.0.0.0:9000
              - name: HADOOP_HOST
                value: 0.0.0.0
              volumeMounts:
                - mountPath: /usr/share/pod
                  name: signal-volume
                  readOnly: true
              # imagePullPolicy: Always
              # resources:
              #   requests:
              #     cpu: 3
              #     memory: 4Gi
              command: ["/bin/bash" ]
              args: 
                - "-c"
                - |
                  trap 'exit 0' SIGINT SIGQUIT SIGTERM
                  # get /usr/local/share/ca-certificates/cdis-ca.crt into system bundle
                  # ssh server sudo /etc/init.d/ssh start
                  # update-ca-certificates
                  python run_config.py
                  hdfs namenode -format
                  hdfs --daemon start namenode
                  hdfs --daemon start datanode
                  yarn --daemon start resourcemanager
                  yarn --daemon start nodemanager
                  hdfs dfsadmin -safemode leave
                  hdfs dfs -mkdir /result
                  hdfs dfs -mkdir /jars
                  hdfs dfs -mkdir /archive
                  /spark/sbin/start-all.sh
                  while true; do sleep 5; done
            - name: tube
              imagePullPolicy: Always
              image: quay.io/cdis/tube:feat_helm_test
              ports:
                - containerPort: 80
              env:
                - name: DB_HOST
                  valueFrom:
                    secretKeyRef:
                      name: peregrine-dbcreds
                      key: host
                - name: DB_DATABASE
                  valueFrom:
                    secretKeyRef:
                      name: sheepdog-dbcreds
                      key: database
                - name: DB_USERNAME
                  valueFrom:
                    secretKeyRef:
                      name: sheepdog-dbcreds
                      key: username
                - name: DB_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: sheepdog-dbcreds
                      key: password
                - name: DB_PORT
                  valueFrom:
                    secretKeyRef:
                      name: sheepdog-dbcreds
                      key: port
                - name: DB_USE_SSL
                  value: "False"
                - name: DICTIONARY_URL
                  valueFrom:
                    configMapKeyRef:
                      name: manifest-global
                      key: dictionary_url
                - name: HADOOP_URL
                  value: hdfs://localhost:9000
                - name: ES_URL
                  value: gen3-elasticsearch-master
                - name: HADOOP_HOST
                  value: localhost
                - name: HADOOP_CLIENT_OPTS
                  value: -Xmx1g
                - name: SPARK_EXECUTOR_MEMORY
                  value: 4g
                - name: SPARK_DRIVER_MEMORY
                  value: 6g
                - name: ETL_FORCED
                  value: "TRUE"
                - name: gen3Env
                  valueFrom:
                    configMapKeyRef:
                      name: manifest-global
                      key: hostname
                - name: slackWebHook
                  valueFrom:
                    configMapKeyRef:
                      name: global
                      key: slack_webhook
                      optional: true
              volumeMounts:
                # - name: "creds-volume"
                #   readOnly: true
                #   mountPath: "/gen3/tube/creds.json"
                #   subPath: creds.json
                # Volume to signal when to kill spark
                - mountPath: /usr/share/pod
                  name: signal-volume
                - name: "etl-mapping"
                  readOnly: true
                  mountPath: "/gen3/tube/etlMapping.yaml"
                  subPath: "etlMapping.yaml"
                - name: "fence-yaml"
                  readOnly: true
                  mountPath: "/gen3/tube/user.yaml"
                  subPath: useryaml
              # resources:
              #   limits:
              #     cpu: 1
              #     memory: 10Gi
              command: ["/bin/bash"]
              args:
                - "-c"
                - |
                  while ! bash -c "echo >/dev/tcp/localhost/9000"; do
                    echo "Spark is not ready on port 9000... waiting for 10 seconds."
                    sleep 10
                  done

                  # Port 9000 is open, continue with the rest of the script
                  echo "Port 9000 is now open. Continuing with the script..."

                  echo "python run_config.py && python run_etl.py"
                  python run_config.py && python run_etl.py
                  # echo 'options use-vc' >> /etc/resolv.conf
                  # if [[ $ETL_FORCED != "false" ]]; then
                  #   python run_config.py && python run_etl.py --force
                  # else
                  #   python run_config.py && python run_etl.py
                  # fi
                  # exitcode=$?
                  # if [[ "${slackWebHook}" != 'None' ]]; then
                  #   if [[ $exitcode == 1 ]]; then
                  #     curl -X POST --data-urlencode "payload={\"text\": \"JOBFAIL: ETL job on ${gen3Env}\"}" "${slackWebHook}"
                  #   else
                  #     curl -X POST --data-urlencode "payload={\"text\": \"SUCCESS: ETL job on ${gen3Env}\"}" "${slackWebHook}"
                  #   fi
                  # fi
                  # echo "Exit code: $exitcode"
                  # exit "$exitcode"
                  # Kill sidecar and all processes
                  pkill -u root
          restartPolicy: Never
